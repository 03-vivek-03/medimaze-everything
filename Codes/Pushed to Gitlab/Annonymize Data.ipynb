{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37e75064-2756-42e1-9fb9-c928301c23f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e38d45c7928433d8809c1c1d9b95c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4 folders with extracted details saved to 'details.xlsx'.\n",
      "Folders with no report: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a74bf2b25f4b0da46f5004d789e5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing DICOM files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from paddleocr import PaddleOCR\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import shutil\n",
    "import logging\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import warnings\n",
    "import pydicom\n",
    "import requests\n",
    "\n",
    "\n",
    "# Set logging level for PaddleOCR\n",
    "logging.getLogger(\"ppocr\").setLevel(logging.ERROR)\n",
    "\n",
    "# Initialize PaddleOCR\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydicom\")\n",
    "\n",
    "# Initialize global DataFrame variables\n",
    "done_df = pd.DataFrame(columns=['Folder'])\n",
    "not_done_df = pd.DataFrame(columns=['Folder'])\n",
    "\n",
    "# Function to save DataFrames to Excel\n",
    "def save_dataframes():\n",
    "    global done_df, not_done_df, done_file, not_done_file\n",
    "    done_df.to_excel(done_file, index=False)\n",
    "    not_done_df.to_excel(not_done_file, index=False)\n",
    "    # print(\"DataFrames saved to Excel.\")\n",
    "\n",
    "def extract_image_tags(soup):\n",
    "    img_tags = soup.find_all('img')\n",
    "    for img_tag in img_tags:\n",
    "        src = img_tag['src']\n",
    "        if src.startswith('http://') or src.startswith('https://'):\n",
    "            image = url_to_image(src)\n",
    "        else:\n",
    "            base64str = src\n",
    "            image = base64_to_image(base64str)\n",
    "            \n",
    "        if image is None:\n",
    "            continue\n",
    "        image = np.array(image)\n",
    "        \n",
    "        result = ocr.ocr(image, cls=True)\n",
    "        extracted_text = ' '.join([element[1][0] for line in result if line for element in line if element])\n",
    "        \n",
    "        pattern = r\"Reg(.*)\"\n",
    "        match = re.search(pattern, extracted_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            reg_no = f\"Reg. No.{match.group(1).strip()}\"\n",
    "            return src, reg_no, extracted_text\n",
    "    return None, None, None\n",
    "\n",
    "def base64_to_image(base64str):\n",
    "    base64_string = base64str.split(\",\")[-1]\n",
    "    \n",
    "    # Fix padding issues in base64 string\n",
    "    missing_padding = len(base64_string) % 4\n",
    "    if missing_padding:\n",
    "        base64_string += '=' * (4 - missing_padding)\n",
    "    \n",
    "    try:\n",
    "        image_data = base64.b64decode(base64_string)\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "        return image\n",
    "    except (UnidentifiedImageError, base64.binascii.Error) as e:\n",
    "        logging.warning(f\"Unidentified image file or invalid base64 string: {e}\")\n",
    "        return None\n",
    "\n",
    "def url_to_image(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        image_data = BytesIO(response.content)\n",
    "        image = Image.open(image_data)\n",
    "        return image\n",
    "    except (requests.RequestException, UnidentifiedImageError) as e:\n",
    "        logging.warning(f\"Failed to fetch or identify image from URL: {url} - {e}\")\n",
    "        return None\n",
    "\n",
    "def replace_image_with_text(soup, original_src, text):\n",
    "    img_tag = None\n",
    "    for tag in soup.find_all('img'):\n",
    "        if original_src in tag['src']:\n",
    "            img_tag = tag\n",
    "            break\n",
    "    if img_tag:\n",
    "        img_tag.replace_with(text)\n",
    "\n",
    "def extract_patient_details_from_table(soup):\n",
    "    table = soup.find('table', {'border': '1', 'cellapdding': '0', 'cellspacing': '0'})\n",
    "    \n",
    "    if not table:\n",
    "        return None, None, None, None, None, None, None, None, None\n",
    "    \n",
    "    patient_id = None\n",
    "    patient_name = None\n",
    "    age = None\n",
    "    sex = None\n",
    "    accession = None\n",
    "    modality = None\n",
    "    physician = None\n",
    "    study = None\n",
    "    study_date = None\n",
    "    \n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) == 4:\n",
    "            key1, value1 = cells[0].get_text(strip=True), cells[1].get_text(strip=True)\n",
    "            key2, value2 = cells[2].get_text(strip=True), cells[3].get_text(strip=True)\n",
    "            \n",
    "            if key1 == \"Patient ID:\":\n",
    "                patient_id = value1\n",
    "            elif key1 == \"Patient Name:\":\n",
    "                patient_name = value1\n",
    "            elif key1 == \"Age:\":\n",
    "                age = value1\n",
    "            elif key1 == \"Sex:\":\n",
    "                sex = value1\n",
    "            elif key1 == \"Accession:\":\n",
    "                accession = value1\n",
    "            elif key1 == \"Modality:\":\n",
    "                modality = value1\n",
    "            elif key1 == \"Physician:\":\n",
    "                physician = value1\n",
    "            elif key1 == \"Study:\":\n",
    "                study = value1\n",
    "            elif key1 == \"Study Date:\":\n",
    "                study_date = value1\n",
    "            \n",
    "            if key2 == \"Patient ID:\":\n",
    "                patient_id = value2\n",
    "            elif key2 == \"Patient Name:\":\n",
    "                patient_name = value2\n",
    "            elif key2 == \"Age:\":\n",
    "                age = value2\n",
    "            elif key2 == \"Sex:\":\n",
    "                sex = value2\n",
    "            elif key2 == \"Accession:\":\n",
    "                accession = value2\n",
    "            elif key2 == \"Modality:\":\n",
    "                modality = value2\n",
    "            elif key2 == \"Physician:\":\n",
    "                physician = value2\n",
    "            elif key2 == \"Study:\":\n",
    "                study = value2\n",
    "            elif key2 == \"Study Date:\":\n",
    "                study_date = value2\n",
    "\n",
    "    age_match = re.search(r'\\d+', patient_name)\n",
    "    if (age_match):\n",
    "        age = patient_name[age_match.start():].strip()\n",
    "        # Remove the age part from patient_name_value\n",
    "        patient_name = patient_name[:age_match.start()].strip()\n",
    "    \n",
    "    return patient_id, patient_name, age, sex, accession, modality, physician, study, study_date\n",
    "\n",
    "def erase_and_save_details(input_folder, error_folder):\n",
    "    global done_df, not_done_df, done_file, not_done_file\n",
    "    count = 0\n",
    "    no_report = []\n",
    "\n",
    "    # Initialize an empty DataFrame to store the extracted data\n",
    "    columns = [\"Folder\", \"Patient ID\", \"Patient Name\", \"Age\", \"Gender\", \"Study\", \"Modality\", \"Study Date\", \"Accession\", \"Physician\", \"Extracted Text\", \"Reg No\"]\n",
    "    data_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Load existing done folders from Excel if it exists\n",
    "    done = []\n",
    "    done_file = os.path.join(error_folder, 'done_folders.xlsx')\n",
    "    not_done_file = os.path.join(error_folder, 'not_done_folders.xlsx')\n",
    "    \n",
    "    if os.path.exists(done_file):\n",
    "        done_df = pd.read_excel(done_file)\n",
    "        done = done_df['Folder'].tolist()\n",
    "    \n",
    "    # Ensure directories exist\n",
    "    os.makedirs(error_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through each folder in the input folder\n",
    "    for folder in tqdm(os.listdir(input_folder)):\n",
    "        if folder not in done:\n",
    "            inside_folder = os.path.join(input_folder, folder)\n",
    "            html_files = [f for f in os.listdir(inside_folder) if f.endswith('.html')]\n",
    "            \n",
    "            if not html_files:\n",
    "                shutil.move(inside_folder, os.path.join(error_folder, folder))\n",
    "                no_report.append(folder)\n",
    "            else:\n",
    "                for filename in os.listdir(inside_folder):\n",
    "                    if filename.startswith('Approved'):              \n",
    "                        # Read the HTML file\n",
    "                        report_file_path = os.path.join(inside_folder, filename)\n",
    "                        \n",
    "                        with open(report_file_path, 'rb') as f:\n",
    "                            raw_data = f.read()\n",
    "                            encoding_result = chardet.detect(raw_data)\n",
    "                            file_encoding = encoding_result['encoding']\n",
    "        \n",
    "                        with open(report_file_path, 'r', encoding=file_encoding) as f:\n",
    "                            content = f.read()\n",
    "        \n",
    "                        soup = BeautifulSoup(content, 'html.parser')\n",
    "        \n",
    "                        src, reg_no, extracted_text = extract_image_tags(soup)\n",
    "        \n",
    "                        if src and reg_no:    \n",
    "                            patient_name_value = None\n",
    "                            patient_id_value = None\n",
    "                            age_value = None\n",
    "                            sex_value = None\n",
    "                            study_value = None\n",
    "                            modality_value = None\n",
    "                            study_date_value = None\n",
    "                            accession_value = None\n",
    "                            physician_value = None\n",
    "        \n",
    "                            # Find and erase 'Patient Name' and 'Patient ID' values\n",
    "                            for tag in soup.find_all('td'):\n",
    "                                if tag.find('b') and 'Patient Name' in tag.find('b').text:\n",
    "                                    patient_name_value = tag.get_text().strip().replace('Patient Name:', '').strip()\n",
    "                                    age_match = re.search(r'\\d+', patient_name_value)\n",
    "                                    if (age_match):\n",
    "                                        age_value = patient_name_value[age_match.start():].strip()\n",
    "                                        # Remove the age part from patient_name_value\n",
    "                                        patient_name_value = patient_name_value[:age_match.start()].strip()\n",
    "                                    # Replace text after 'Patient Name' with empty string\n",
    "                                    tag.contents[-1].replace_with('')\n",
    "        \n",
    "                                if tag.find('b') and 'Patient ID' in tag.find('b').text:\n",
    "                                    patient_id_value = tag.get_text().strip().replace('Patient ID:', '').strip()\n",
    "                                    tag.contents[-1].replace_with('')\n",
    "        \n",
    "                                if tag.find('b') and 'Sex' in tag.find('b').text:\n",
    "                                    sex_value = tag.get_text().strip().replace('Sex:', '').strip()\n",
    "        \n",
    "                                if tag.find('b') and 'Study' in tag.find('b').text and not 'Study ' in tag.find('b').text:\n",
    "                                    study_value = tag.get_text().strip().replace('Study:', '').strip()\n",
    "        \n",
    "                                if tag.find('b') and 'Modality' in tag.find('b').text:\n",
    "                                    modality_value = tag.get_text().strip().replace('Modality:', '').strip()\n",
    "        \n",
    "                                if tag.find('b') and 'Study Date' in tag.find('b').text:\n",
    "                                    study_date_value = tag.get_text().strip().replace('Study Date:', '').strip()\n",
    "                                    tag.contents[-1].replace_with('')\n",
    "        \n",
    "                                if tag.find('b') and 'Accession' in tag.find('b').text:\n",
    "                                    accession_value = tag.get_text().strip().replace('Accession Number:', '').strip()\n",
    "                                    tag.contents[-1].replace_with('')\n",
    "        \n",
    "                                if tag.find('b') and 'Physician' in tag.find('b').text:\n",
    "                                    physician_value = tag.get_text().strip().replace('Referring Physician:', '').strip()\n",
    "                                    tag.contents[-1].replace_with('')\n",
    "\n",
    "                            # Insert the age value into the <b>Age</b> tag if it exists\n",
    "                            if age_value:\n",
    "                                for tag in soup.find_all('td'):\n",
    "                                    if tag.find('b') and 'Age' in tag.find('b').text:\n",
    "                                        # Replace ':' with ': ' + age_value\n",
    "                                        tag.contents[-1].replace_with(f':{age_value}')\n",
    "                            else:\n",
    "                                for tag in soup.find_all('td'):\n",
    "                                    if tag.find('b') and 'Age' in tag.find('b').text:\n",
    "                                        age_value = tag.get_text().strip().replace('Age:', '').strip()\n",
    "                                        if not age_value:\n",
    "                                            age_value = \"0\"\n",
    "        \n",
    "                            # Use the new extraction function if primary extraction fails\n",
    "                            if not any([patient_name_value, patient_id_value, age_value, sex_value, study_value, modality_value, study_date_value, accession_value, physician_value]):\n",
    "                                (patient_id_value, patient_name_value, age_value, sex_value, accession_value, modality_value, physician_value, study_value, study_date_value) = extract_patient_details_from_table(soup)\n",
    "        \n",
    "                            # Add the extracted values to the DataFrame\n",
    "                            new_row = {\n",
    "                                \"Folder\": folder,\n",
    "                                \"Patient ID\": patient_id_value,\n",
    "                                \"Patient Name\": patient_name_value,\n",
    "                                \"Age\": age_value,\n",
    "                                \"Gender\": sex_value,\n",
    "                                \"Study\": study_value,\n",
    "                                \"Modality\": modality_value,\n",
    "                                \"Study Date\": study_date_value,\n",
    "                                \"Accession\": accession_value,\n",
    "                                \"Physician\": physician_value,\n",
    "                                \"Extracted Text\": extracted_text,\n",
    "                                \"Reg No\": reg_no\n",
    "                            }\n",
    "                            \n",
    "                            data_df = pd.concat([data_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "                            replace_image_with_text(soup, src, reg_no)\n",
    "        \n",
    "                            new_file = os.path.join(inside_folder, filename.replace('Approved', 'Annonymized'))\n",
    "                            with open(new_file, 'w', encoding=file_encoding) as file:\n",
    "                                file.write(str(soup))\n",
    "                            os.remove(os.path.join(inside_folder, filename))\n",
    "        \n",
    "                            count += 1\n",
    "                            done_df = pd.concat([done_df, pd.DataFrame({\"Folder\": [folder]})], ignore_index=True)\n",
    "                            save_dataframes()\n",
    "        \n",
    "                        else:\n",
    "                            not_done_df = pd.concat([not_done_df, pd.DataFrame({\"Folder\": [folder]})], ignore_index=True)\n",
    "                            save_dataframes()\n",
    "    \n",
    "    data_df.to_excel(os.path.join(error_folder, \"details.xlsx\"), index=False)\n",
    "    print(f\"Processed {count} folders with extracted details saved to 'details.xlsx'.\")\n",
    "    print(f\"Folders with no report: {len(no_report)}\")\n",
    "\n",
    "    # Save the DataFrames to Excel after processing all folders\n",
    "    save_dataframes()\n",
    "\n",
    "def modify_dicom_files(root_path, excel_path):\n",
    "    # Check if the master Excel file exists\n",
    "    if os.path.exists(excel_path):\n",
    "        institution_df = pd.read_excel(excel_path)\n",
    "    else:\n",
    "        institution_df = pd.DataFrame(columns=[\"InstitutionName\", \"Counter\"])\n",
    "\n",
    "    dicom_files = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.dic'):\n",
    "                dicom_files.append(os.path.join(root, file))\n",
    "\n",
    "    for dicom_path in tqdm(dicom_files, desc=\"Processing DICOM files\"):\n",
    "        dicom_image = pydicom.dcmread(dicom_path, force=True)\n",
    "\n",
    "        # Check if PatientName attribute exists\n",
    "        if hasattr(dicom_image, 'PatientName'):\n",
    "            # Extract the patient's age from PatientName\n",
    "            patient_name = str(dicom_image.PatientName)\n",
    "            age_match = re.search(r'(\\d+)(?:Y(?:rs?)?|Year?)$', patient_name, re.IGNORECASE)\n",
    "            if age_match:\n",
    "                dicom_image.PatientAge = age_match.group(1)\n",
    "\n",
    "            # Delete the PatientName, PatientID, and InstitutionName tags\n",
    "            del dicom_image.PatientName\n",
    "            del dicom_image.PatientID\n",
    "            \n",
    "        tag_numbers = [(0x0021, 0x0012), (0x0400, 0x0561), (0x0009, 0x0010), (0x0008, 0x1070), (0x0002, 0x0013), (0x0008, 0x0090), (0x0002, 0x0016), (0x0010, 0x0020)]\n",
    "\n",
    "        # Handle the InstitutionName tag\n",
    "        if hasattr(dicom_image, 'InstitutionName'):\n",
    "            institution_name = str(dicom_image.InstitutionName)\n",
    "            if institution_name not in institution_df['InstitutionName'].values:\n",
    "                new_counter = len(institution_df) + 1\n",
    "                new_entry = pd.DataFrame({\"InstitutionName\": [institution_name], \"Counter\": [new_counter]})\n",
    "                institution_df = pd.concat([institution_df, new_entry], ignore_index=True)\n",
    "            else:\n",
    "                new_counter = institution_df[institution_df['InstitutionName'] == institution_name]['Counter'].values[0]\n",
    "            dicom_image.InstitutionName = str(new_counter)\n",
    "\n",
    "        for tag_number in tag_numbers:\n",
    "            if tag_number in dicom_image:\n",
    "                del dicom_image[tag_number]\n",
    "\n",
    "        # Save the modified DICOM image with the same name\n",
    "        try:\n",
    "            dicom_image.save_as(dicom_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving DICOM file: {dicom_path}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    institution_df.to_excel(excel_path, index=False)\n",
    "\n",
    "input_folder = r\"E:\\Anonymize app\\data\"\n",
    "input_folder = input_folder.replace('\\\\','/')\n",
    "error_folder = input_folder + \"-err\"\n",
    "\n",
    "# Call the function\n",
    "erase_and_save_details(input_folder, error_folder)\n",
    "\n",
    "excel_path = error_folder + \"/institute.xlsx\"\n",
    "\n",
    "modify_dicom_files(input_folder, excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2dee8-a555-4527-8ffc-2e25ddb2ea81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
