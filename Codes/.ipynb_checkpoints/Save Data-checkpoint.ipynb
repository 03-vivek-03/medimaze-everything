{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480d6a43",
   "metadata": {},
   "source": [
    "#Print HTML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8437887",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = None\n",
    "keywords = ['normal study', 'no significant abnorm', 'no significant\\nabnorm'] \n",
    "for keyword in ['impression', 'conclusion']:\n",
    "    if keyword in text:\n",
    "        # Get text after the keyword and limit to 500 characters\n",
    "        start_index = text.index(keyword) + len(keyword)\n",
    "        extracted_text = text[start_index:start_index + 500].strip()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "586d077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-16\n",
      "patient id:op 2335patient name:gayathri 26yage:sex:faccession number:modality:crreferring physician:study:knee latstudy date:9-jan-2023\n",
      "\n",
      " \n",
      "x-ray\n",
      "right knee ( lat)\n",
      "\n",
      "\n",
      "technique: - 2 view obtained.\n",
      "\n",
      "clinical history: - not\n",
      "provided.\n",
      "\n",
      "findings: -    \n",
      " \n",
      "alignment of right knee joint is normal.\n",
      " \n",
      "articular margins and joint space is normal.\n",
      " \n",
      "no obvious bony injury.\n",
      " \n",
      "bone density is normal. \n",
      " \n",
      "impression: - no significant\n",
      "abnormality\n",
      "\n",
      "\n",
      "advice:\n",
      "- clinical correlation and follow up\n",
      " \n",
      "disclaimer: report is done by teleradiology\n",
      "after the images acquired by pacs (picture archiving and communication system).\n",
      "investigations have their limitations. solitary pathological/radiological and\n",
      "other investigations never confirm the final diagnosis. conclusion is markedly\n",
      "affected by input provided at that time. they only help in diagnosing the\n",
      "disease in correlation to clinical symptoms and other related tests. please\n",
      "interpret accordingly.\n",
      " \n",
      "     \n",
      "  date: 9-jan-2023\n",
      "------------------------------\n",
      "Patient ID: op 2335\n",
      "Patient Name: gayathri 26y\n",
      "Age: \n",
      "Sex: f\n",
      "Accession Number: \n",
      "Modality: cr\n",
      "Referring Physician: \n",
      "Study: knee lat\n",
      "Study Date: None\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet\n",
    "\n",
    "def extract_patient_details_from_text(content):\n",
    "    patterns = {\n",
    "        \"Patient ID\": r\"patient id:\\s*(.*?)\\s*patient name:\",\n",
    "        \"Patient Name\": r\"patient name:\\s*(.*?)\\s*age:\",\n",
    "        \"Age\": r\"age:\\s*(.*?)\\s*sex:\",\n",
    "        \"Sex\": r\"sex:\\s*(.*?)\\s*accession number:\",\n",
    "        \"Accession\": r\"accession number:\\s*(.*?)\\s*modality:\",\n",
    "        \"Modality\": r\"modality:\\s*(.*?)\\s*referring physician:\",\n",
    "        \"Physician\": r\"referring physician:\\s*(.*?)\\s*study:\",\n",
    "        \"Study\": r\"study:\\s*(.*?)\\s*study date:\",\n",
    "        \"Study Date\": r\"study date:\\s*(\\d{2}-\\w{3}-\\d{4})\"\n",
    "    }\n",
    "\n",
    "    patient_details = {}\n",
    "\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        if match:\n",
    "            patient_details[key] = match.group(1).strip()\n",
    "        else:\n",
    "            patient_details[key] = None\n",
    "\n",
    "    return (\n",
    "        patient_details.get(\"Patient ID\"),\n",
    "        patient_details.get(\"Patient Name\"),\n",
    "        patient_details.get(\"Age\"),\n",
    "        patient_details.get(\"Sex\"),\n",
    "        patient_details.get(\"Accession\"),\n",
    "        patient_details.get(\"Modality\"),\n",
    "        patient_details.get(\"Physician\"),\n",
    "        patient_details.get(\"Study\"),\n",
    "        patient_details.get(\"Study Date\")\n",
    "    )\n",
    "\n",
    "report_file_path = r\"D:\\NEW HILAR PROMINENCE\\Org datasets\\Final_1.2.392.200036.9125.2.140220212691585.6524341095.3280176.html\"\n",
    "\n",
    "with open(report_file_path, 'rb') as f:\n",
    "    raw_data = f.read()\n",
    "    encoding_result = chardet.detect(raw_data)\n",
    "    file_encoding = encoding_result['encoding']\n",
    "    print(file_encoding)\n",
    "\n",
    "with open(report_file_path, 'r', encoding=file_encoding) as f:\n",
    "    content = f.read()\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "text = soup.get_text().lower().strip()\n",
    "\n",
    "patient_id, patient_name, age, sex, accession, modality, physician, study, study_date = extract_patient_details_from_text(text)\n",
    "\n",
    "result = \"Normal\" if \"no significant abnorm\" in text else \"Abnormal\"\n",
    "\n",
    "# Determine if the report is normal or abnormal\n",
    "result = \"Normal\" if (\"no significant abnorm\" in text or \"no significant\\nabnorm\" in text) else \"Abnormal\"\n",
    "\n",
    "print(text)\n",
    "print(\"-\" * 30)\n",
    "print(\"Patient ID:\", patient_id)\n",
    "print(\"Patient Name:\", patient_name)\n",
    "print(\"Age:\", age)\n",
    "print(\"Sex:\", sex)\n",
    "print(\"Accession Number:\", accession)\n",
    "print(\"Modality:\", modality)\n",
    "print(\"Referring Physician:\", physician)\n",
    "print(\"Study:\", study)\n",
    "print(\"Study Date:\", study_date)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08be18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea57f3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: UTF-16\n",
      "All Text: patient id :op 2335 patient name :gayathri 26y age : sex :f accession number : modality :cr referring physician : study :knee lat study date :9-jan-2023 x-ray\n",
      "right knee ( lat) technique : - 2 view obtained. clinical history : - not\n",
      "provided. findings : - alignment of right knee joint is normal. articular margins and joint space is normal. no obvious bony injury. bone density is normal. impression : - no significant\n",
      "abnormality advice :\n",
      "- clinical correlation and follow up disclaimer: report is done by teleradiology\n",
      "after the images acquired by pacs (picture archiving and communication system).\n",
      "investigations have their limitations. solitary pathological/radiological and\n",
      "other investigations never confirm the final diagnosis. conclusion is markedly\n",
      "affected by input provided at that time. they only help in diagnosing the\n",
      "disease in correlation to clinical symptoms and other related tests. please\n",
      "interpret accordingly. date: 9-jan-2023\n",
      "Editable Data: \n",
      "Editable Data: X-RAY\n",
      "RIGHT KNEE ( LAT)TECHNIQUE: - 2 view obtained.CLINICAL HISTORY: - Not\n",
      "provided.FINDINGS: -Alignment of right knee joint is normal.Articular margins and joint space is normal.No obvious bony injury.Bone density is normal.IMPRESSION: -No significant\n",
      "abnormality\n",
      "Editable Data: Disclaimer: Report is done by teleradiology\n",
      "after the images acquired by PACS (picture archiving and communication system).\n",
      "Investigations have their limitations. Solitary pathological/Radiological and\n",
      "other investigations never confirm the final diagnosis. Conclusion is markedly\n",
      "affected by input provided at that time. They only help in diagnosing the\n",
      "disease in correlation to clinical symptoms and other related tests. Please\n",
      "interpret accordingly.\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "report_file_path = r\"D:\\NEW HILAR PROMINENCE\\Org datasets\\Final_1.2.392.200036.9125.2.140220212691585.6524341095.3280176.html\"\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open(report_file_path, 'rb') as f:\n",
    "    raw_data = f.read()\n",
    "    encoding_result = chardet.detect(raw_data)\n",
    "    file_encoding = encoding_result['encoding']\n",
    "    print(\"Detected encoding:\", file_encoding)\n",
    "\n",
    "# Read the file with the detected encoding\n",
    "with open(report_file_path, 'r', encoding=file_encoding) as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Extract all text\n",
    "text = soup.get_text(separator=' ', strip=True).lower()\n",
    "\n",
    "# Use both div and span but remove duplicates\n",
    "editable_data = soup.find_all(['p'])\n",
    "editable_texts = set()  # Use a set to avoid duplicates\n",
    "\n",
    "for element in editable_data:\n",
    "    editable_texts.add(element.get_text(strip=True))\n",
    "\n",
    "# Convert the set back to a list if needed\n",
    "editable_texts = list(editable_texts)\n",
    "\n",
    "print(\"All Text:\", text)\n",
    "\n",
    "for a in editable_texts:\n",
    "    print(\"Editable Data:\", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96262b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Patient ID:XRG438Patient Name:SHANVI.05/F.A.H,GUDURAge:Sex:OAccession Number:Modality:CRReferring Physician:Study:UP.ARM/ELBOW JNTStudy Date:25-Jan-2023X-RAY RT\\xa0ELBOW AP & LATERAL VIEWFINDINGS :Fracture noted at distal\\xa0humerus with surrounding soft tissue swelling.Rest of visualized bones appear grossly normalSuggest clinical correlation and follow upDate: 25-Jan-2023', '', 'Patient ID:XRG438Patient Name:SHANVI.05/F.A.H,GUDURAge:Sex:OAccession Number:Modality:CRReferring Physician:Study:UP.ARM/ELBOW JNTStudy Date:25-Jan-2023', 'X-RAY RT\\xa0ELBOW AP & LATERAL VIEWFINDINGS :Fracture noted at distal\\xa0humerus with surrounding soft tissue swelling.Rest of visualized bones appear grossly normalSuggest clinical correlation and follow upDate: 25-Jan-2023', '']\n",
      "------------------------------\n",
      "------------------------------\n",
      "Abnormal\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "report_file_path = r\"D:\\NEW HILAR PROMINENCE\\Org datasets\\Final_1.2.392.200036.9125.2.14022021263108217.6525717172.328074.html\"\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open(report_file_path, 'rb') as f:\n",
    "    raw_data = f.read()\n",
    "    encoding_result = chardet.detect(raw_data)\n",
    "    file_encoding = encoding_result['encoding']\n",
    "#     print(\"Detected encoding:\", file_encoding)\n",
    "\n",
    "# Read the file with the detected encoding\n",
    "with open(report_file_path, 'r', encoding=file_encoding) as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Extract all text\n",
    "text = soup.get_text(separator=' ', strip=True).lower()\n",
    "\n",
    "# Try to find editable data in a broader range of tags\n",
    "editable_data = soup.find_all(['div', 'span'])  # Add more tags if necessary\n",
    "editable_texts = [element.get_text(strip=True) for element in editable_data]\n",
    "\n",
    "# print(\"All Text:\", text)\n",
    "print(editable_texts)\n",
    "print(\"-\"*30)\n",
    "result = \"Normal\" if \"no significant abnorm\" in text else \"Abnormal\"\n",
    "print(\"-\"*30)\n",
    "print(result)\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048d18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f27fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8836b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987512f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71751db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6eaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e998ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "# Function to extract patient details\n",
    "def extract_patient_details_from_table(soup):\n",
    "    table = soup.find('table', {'border': '1', 'cellapdding': '0', 'cellspacing': '0'})\n",
    "    \n",
    "    if not table:\n",
    "        return None, None, None, None, None, None, None, None, None\n",
    "    \n",
    "    patient_id = None\n",
    "    patient_name = None\n",
    "    age = None\n",
    "    sex = None\n",
    "    accession = None\n",
    "    modality = None\n",
    "    physician = None\n",
    "    study = None\n",
    "    study_date = None\n",
    "    \n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) == 4:\n",
    "            key1, value1 = cells[0].get_text(strip=True), cells[1].get_text(strip=True)\n",
    "            key2, value2 = cells[2].get_text(strip=True), cells[3].get_text(strip=True)\n",
    "            \n",
    "            if key1 == \"Patient ID:\":\n",
    "                patient_id = value1\n",
    "            elif key1 == \"Patient Name:\":\n",
    "                patient_name = value1\n",
    "            elif key1 == \"Age:\":\n",
    "                age = value1\n",
    "            elif key1 == \"Sex:\":\n",
    "                sex = value1\n",
    "            elif key1 == \"Accession:\":\n",
    "                accession = value1\n",
    "            elif key1 == \"Modality:\":\n",
    "                modality = value1\n",
    "            elif key1 == \"Physician:\":\n",
    "                physician = value1\n",
    "            elif key1 == \"Study:\":\n",
    "                study = value1\n",
    "            elif key1 == \"Study Date:\":\n",
    "                study_date = value1\n",
    "            \n",
    "            if key2 == \"Patient ID:\":\n",
    "                patient_id = value2\n",
    "            elif key2 == \"Patient Name:\":\n",
    "                patient_name = value2\n",
    "            elif key2 == \"Age:\":\n",
    "                age = value2\n",
    "            elif key2 == \"Sex:\":\n",
    "                sex = value2\n",
    "            elif key2 == \"Accession:\":\n",
    "                accession = value2\n",
    "            elif key2 == \"Modality:\":\n",
    "                modality = value2\n",
    "            elif key2 == \"Physician:\":\n",
    "                physician = value2\n",
    "            elif key2 == \"Study:\":\n",
    "                study = value2\n",
    "            elif key2 == \"Study Date:\":\n",
    "                study_date = value2\n",
    "\n",
    "    age_match = re.search(r'\\d+', patient_name)\n",
    "    if age_match:\n",
    "        age = patient_name[age_match.start():].strip()\n",
    "        patient_name = patient_name[:age_match.start()].strip()\n",
    "    \n",
    "    return patient_id, patient_name, age, sex, accession, modality, physician, study, study_date\n",
    "\n",
    "\n",
    "def erase_and_save_details(input_folder, excel_path):\n",
    "    count = 0\n",
    "    no_report = []\n",
    "\n",
    "    # Initialize an empty DataFrame to store the extracted data\n",
    "    columns = [\"Folder\", \"Patient ID\", \"Patient Name\", \"Age\", \"Gender\", \"Study\", \"Modality\", \"Study Date\", \"Accession\", \"Physician\", \"Result\"]\n",
    "    data_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Iterate through each folder in the input folder\n",
    "    for folder in tqdm(os.listdir(input_folder)):\n",
    "        inside_folder = os.path.join(input_folder, folder)\n",
    "        html_files = [f for f in os.listdir(inside_folder) if f.endswith('.html')]\n",
    "\n",
    "        if not html_files:\n",
    "            shutil.move(inside_folder, os.path.join(no_report_path, folder))\n",
    "            no_report.append(folder)\n",
    "        else:\n",
    "            for filename in os.listdir(inside_folder):\n",
    "                if filename.startswith('Final'):              \n",
    "                    # Read the HTML file\n",
    "                    report_file_path = os.path.join(inside_folder, filename)\n",
    "\n",
    "                    with open(report_file_path, 'rb') as f:\n",
    "                        raw_data = f.read()\n",
    "                        encoding_result = chardet.detect(raw_data)\n",
    "                        file_encoding = encoding_result['encoding']\n",
    "\n",
    "                    with open(report_file_path, 'r', encoding=file_encoding) as f:\n",
    "                        content = f.read()\n",
    "\n",
    "                    # Parse the HTML content with BeautifulSoup\n",
    "                    soup = BeautifulSoup(content, 'html.parser')\n",
    "                    \n",
    "                    # Extract the report text\n",
    "                    text = soup.get_text().lower()\n",
    "\n",
    "                    # Determine if the report is normal or abnormal\n",
    "                    result = \"Normal\" if \"no significant abnorm\" in text else \"Abnormal\"\n",
    "\n",
    "                    patient_name_value = None\n",
    "                    patient_id_value = None\n",
    "                    age_value = None\n",
    "                    sex_value = None\n",
    "                    study_value = None\n",
    "                    modality_value = None\n",
    "                    study_date_value = None\n",
    "                    accession_value = None\n",
    "                    physician_value = None\n",
    "\n",
    "                    # Find and erase 'Patient Name' and 'Patient ID' values\n",
    "                    for tag in soup.find_all('td'):\n",
    "                        if tag.find('b') and 'Patient Name' in tag.find('b').text:\n",
    "                            patient_name_value = tag.get_text().strip().replace('Patient Name:', '').strip()\n",
    "                            age_match = re.search(r'\\d+', patient_name_value)\n",
    "                            if age_match:\n",
    "                                age_value = patient_name_value[age_match.start():].strip()\n",
    "                                patient_name_value = patient_name_value[:age_match.start()].strip()\n",
    "\n",
    "                        if tag.find('b') and 'Patient ID' in tag.find('b').text:\n",
    "                            patient_id_value = tag.get_text().strip().replace('Patient ID:', '').strip()\n",
    "\n",
    "                        if tag.find('b') and 'Sex' in tag.find('b').text:\n",
    "                            sex_value = tag.get_text().strip().replace('Sex:', '').strip()\n",
    "\n",
    "                        if tag.find('b') and 'Study' in tag.find('b').text and not 'Study ' in tag.find('b').text:\n",
    "                            study_value = tag.get_text().strip().replace('Study:', '').strip()\n",
    "\n",
    "                        if tag.find('b') and 'Modality' in tag.find('b').text:\n",
    "                            modality_value = tag.get_text().strip().replace('Modality:', '').strip()\n",
    "\n",
    "                        if tag.find('b') and 'Study Date' in tag.find('b').text:\n",
    "                            study_date_value = tag.get_text().strip().replace('Study Date:', '').strip()\n",
    "\n",
    "                        if tag.find('b') and 'Accession' in tag.find('b').text:\n",
    "                            accession_value = tag.get_text().strip().replace('Accession Number:', '').strip()\n",
    "\n",
    "                        if tag.find('b') and 'Physician' in tag.find('b').text:\n",
    "                            physician_value = tag.get_text().strip().replace('Referring Physician:', '').strip()\n",
    "\n",
    "                    # Insert the age value into the <b>Age</b> tag if it exists\n",
    "                    if not age_value:\n",
    "                        age_value = \"0\"\n",
    "\n",
    "                    # Use the new extraction function if primary extraction fails\n",
    "                    if not any([patient_name_value, patient_id_value, sex_value, study_value, modality_value, study_date_value, accession_value, physician_value]):\n",
    "                        (patient_id_value, patient_name_value, age_value, sex_value, accession_value, modality_value, physician_value, study_value, study_date_value) = extract_patient_details_from_table(soup)\n",
    "                    \n",
    "                    # Insert the age value into the <b>Age</b> tag if it exists\n",
    "                    if not age_value:\n",
    "                        age_value = \"0\"\n",
    "                    \n",
    "                    # Add the extracted values to the DataFrame\n",
    "                    new_row = {\n",
    "                        \"Folder\": folder,\n",
    "                        \"Patient ID\": patient_id_value,\n",
    "                        \"Patient Name\": patient_name_value,\n",
    "                        \"Age\": age_value,\n",
    "                        \"Gender\": sex_value,\n",
    "                        \"Study\": study_value,\n",
    "                        \"Modality\": modality_value,\n",
    "                        \"Study Date\": study_date_value,\n",
    "                        \"Accession\": accession_value,\n",
    "                        \"Physician\": physician_value,\n",
    "                        \"Result\": result,\n",
    "                    }\n",
    "                    \n",
    "                    data_df = pd.concat([data_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "                    count += 1\n",
    "    \n",
    "    data_df.to_excel(os.path.join(excel_path, \"details.xlsx\"), index=False)\n",
    "    print(f\"Processed {count} folders with extracted details saved to 'details.xlsx'.\")\n",
    "    print(f\"Folders with no report: {len(no_report)}\")\n",
    "\n",
    "input_folder = \"D:\\NEW HILAR PROMINENCE\\Org datasets\\group1\"\n",
    "excel_path = \"D:\\NEW HILAR PROMINENCE\\Org datasets\"\n",
    "\n",
    "# Call the function\n",
    "erase_and_save_details(input_folder, excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91e2aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9fa15e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5522b3764e004e87b3c522e34cc15c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 folders with extracted details saved to 'details.xlsx'.\n",
      "Folders with no report: 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba98c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b01ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ca6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9483c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c133f34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6651797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chardet\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_patient_details_from_text(content):\n",
    "    # Define regex patterns to extract patient details\n",
    "    patterns = {\n",
    "        \"Patient ID\": r\"Patient ID:\\s*(.*?)\\s*Patient Name:\",\n",
    "        \"Patient Name\": r\"Patient Name:\\s*(.*?)\\s*Age:\",\n",
    "        \"Age\": r\"Age:\\s*(.*?)\\s*Sex:\",\n",
    "        \"Sex\": r\"Sex:\\s*(.*?)\\s*Accession Number:\",\n",
    "        \"Accession\": r\"Accession Number:\\s*(.*?)\\s*Modality:\",\n",
    "        \"Modality\": r\"Modality:\\s*(.*?)\\s*Referring Physician:\",\n",
    "        \"Physician\": r\"Referring Physician:\\s*(.*?)\\s*Study:\",\n",
    "        \"Study\": r\"Study:\\s*(.*?)\\s*Study Date:\",\n",
    "        \"Study Date\": r\"Study Date:\\s*(\\d{2}-\\w{3}-\\d{4})\"  # Matches dd-mmm-yyyy format\n",
    "    }\n",
    "\n",
    "    patient_details = {}\n",
    "\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        if match:\n",
    "            patient_details[key] = match.group(1).strip()\n",
    "        else:\n",
    "            patient_details[key] = None  # Assign None if not found\n",
    "\n",
    "    return (\n",
    "        patient_details.get(\"Patient ID\"),\n",
    "        patient_details.get(\"Patient Name\"),\n",
    "        patient_details.get(\"Age\"),\n",
    "        patient_details.get(\"Sex\"),\n",
    "        patient_details.get(\"Accession\"),\n",
    "        patient_details.get(\"Modality\"),\n",
    "        patient_details.get(\"Physician\"),\n",
    "        patient_details.get(\"Study\"),\n",
    "        patient_details.get(\"Study Date\")\n",
    "    )\n",
    "\n",
    "# Main loop\n",
    "main_path = r\"D:\\NEW HILAR PROMINENCE\\Org datasets\\group1\"\n",
    "\n",
    "for folder in tqdm(os.listdir(main_path), leave=False):\n",
    "    new_path = os.path.join(main_path, folder)\n",
    "    for fol in os.listdir(new_path):\n",
    "        if fol.startswith('Approved'):\n",
    "            report_file_path = os.path.join(new_path, fol)\n",
    "            try:\n",
    "                with open(report_file_path, 'rb') as f:\n",
    "                    raw_data = f.read()\n",
    "                    encoding_result = chardet.detect(raw_data)\n",
    "                    file_encoding = encoding_result['encoding']\n",
    "\n",
    "                with open(report_file_path, 'r', encoding=file_encoding) as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "                # Extract patient details using text scraping\n",
    "                patient_id, patient_name, age, sex, accession, modality, physician, study, study_date = extract_patient_details_from_text(content)\n",
    "\n",
    "                # Extract the report text\n",
    "                text = soup.get_text().lower()\n",
    "\n",
    "                # Determine if the report is normal or abnormal\n",
    "                result = \"Normal\" if \"no significant abnorm\" in text else \"Abnormal\"\n",
    "\n",
    "                # Append the data to the list\n",
    "                data.append([folder, patient_id, patient_name, age, sex, accession, modality, study, study_date, result])\n",
    "\n",
    "            except FileNotFoundError as e:\n",
    "                continue\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Folder\", \"Patient ID\", \"Patient Name\", \"Age\", \"Sex\", \"Accession\", \"Modality\", \"Study\", \"Study Date\", \"Result\"])\n",
    "\n",
    "\n",
    "output_file = \"D:/NEW HILAR PROMINENCE/Org datasets/patient_details.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Data exported to {output_file} successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0dc879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c42a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed14b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284d09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d96b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chardet\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Function to extract patient details\n",
    "def extract_patient_details_from_table(soup):\n",
    "    table = soup.find('table', {'border': '1', 'cellapdding': '0', 'cellspacing': '0'})\n",
    "    \n",
    "    if not table:\n",
    "        return None, None, None, None, None, None, None, None, None\n",
    "    \n",
    "    patient_id = None\n",
    "    patient_name = None\n",
    "    age = None\n",
    "    sex = None\n",
    "    accession = None\n",
    "    modality = None\n",
    "    physician = None\n",
    "    study = None\n",
    "    study_date = None\n",
    "    \n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) == 4:\n",
    "            key1, value1 = cells[0].get_text(strip=True), cells[1].get_text(strip=True)\n",
    "            key2, value2 = cells[2].get_text(strip=True), cells[3].get_text(strip=True)\n",
    "            \n",
    "            if key1 == \"Patient ID:\":\n",
    "                patient_id = value1\n",
    "            elif key1 == \"Patient Name:\":\n",
    "                patient_name = value1\n",
    "            elif key1 == \"Age:\":\n",
    "                age = value1\n",
    "            elif key1 == \"Sex:\":\n",
    "                sex = value1\n",
    "            elif key1 == \"Accession:\":\n",
    "                accession = value1\n",
    "            elif key1 == \"Modality:\":\n",
    "                modality = value1\n",
    "            elif key1 == \"Physician:\":\n",
    "                physician = value1\n",
    "            elif key1 == \"Study:\":\n",
    "                study = value1\n",
    "            elif key1 == \"Study Date:\":\n",
    "                study_date = value1\n",
    "            \n",
    "            if key2 == \"Patient ID:\":\n",
    "                patient_id = value2\n",
    "            elif key2 == \"Patient Name:\":\n",
    "                patient_name = value2\n",
    "            elif key2 == \"Age:\":\n",
    "                age = value2\n",
    "            elif key2 == \"Sex:\":\n",
    "                sex = value2\n",
    "            elif key2 == \"Accession:\":\n",
    "                accession = value2\n",
    "            elif key2 == \"Modality:\":\n",
    "                modality = value2\n",
    "            elif key2 == \"Physician:\":\n",
    "                physician = value2\n",
    "            elif key2 == \"Study:\":\n",
    "                study = value2\n",
    "            elif key2 == \"Study Date:\":\n",
    "                study_date = value2\n",
    "\n",
    "    age_match = re.search(r'\\d+', patient_name)\n",
    "    if age_match:\n",
    "        age = patient_name[age_match.start():].strip()\n",
    "        patient_name = patient_name[:age_match.start()].strip()\n",
    "    \n",
    "    return patient_id, patient_name, age, sex, accession, modality, physician, study, study_date\n",
    "\n",
    "# Initialize list to hold data\n",
    "data = []\n",
    "# Main loop\n",
    "main_path = r\"D:\\NEW HILAR PROMINENCE\\Org datasets\\group1\"\n",
    "\n",
    "for folder in tqdm(os.listdir(main_path), leave=False):\n",
    "    new_path = os.path.join(main_path, folder)\n",
    "    for fol in os.listdir(new_path):\n",
    "        if fol.startswith('Approved'):\n",
    "            report_file_path = os.path.join(new_path, fol)\n",
    "            try:\n",
    "                with open(report_file_path, 'rb') as f:\n",
    "                    raw_data = f.read()\n",
    "                    encoding_result = chardet.detect(raw_data)\n",
    "                    file_encoding = encoding_result['encoding']\n",
    "\n",
    "                with open(report_file_path, 'r', encoding=file_encoding) as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "                # Extract patient details\n",
    "                patient_id, patient_name, age, sex, accession, modality, physician, study, study_date = extract_patient_details_from_table(soup)\n",
    "\n",
    "                # Extract the report text\n",
    "                text = soup.get_text().lower()\n",
    "\n",
    "                # Determine if the report is normal or abnormal\n",
    "                result = \"Normal\" if \"no significant abnorm\" in text else \"Abnormal\"\n",
    "\n",
    "                # Append the data to the list\n",
    "                data.append([folder, patient_id, patient_name, age, sex, accession, modality, study, study_date, result])\n",
    "\n",
    "            except FileNotFoundError as e:\n",
    "                continue\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Folder\", \"Patient ID\", \"Patient Name\", \"Age\", \"Sex\", \"Accession\", \"Modality\", \"Study\", \"Study Date\", \"Result\"])\n",
    "\n",
    "\n",
    "output_file = \"D:/NEW HILAR PROMINENCE/Org datasets/patient_details.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Data exported to {output_file} successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa71e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
